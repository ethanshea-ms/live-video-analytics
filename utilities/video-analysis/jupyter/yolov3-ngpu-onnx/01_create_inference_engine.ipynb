{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": [
        "# 1. Create YoloV3 Inference Engine\n",
        "In this section, we will create an inference engine wrapper, a class that will get an image data as input, analyse it and return analysis result."
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## 1.1. Get global variables\n",
        "We will read the previously stored variables. We need the name of the directory that we will use to store in our ml solution files. We create a directory with the specified directory name (if not already exist)"
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "from dotenv import set_key, get_key, find_dotenv\n",
        "envPath = find_dotenv(raise_error_if_not_found=True)\n",
        "\n",
        "isSolutionPath = get_key(envPath, \"isSolutionPath\")\n",
        "\n",
        "import os\n",
        "if not os.path.exists(isSolutionPath):\n",
        "    os.mkdir(isSolutionPath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## 5.2. Download ONNX ML model\n",
        "Download sample ONNX Model to use in the solution. You can customize it with your own ONNX model and solution."
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "# dont change below values as it will be embedded into score.py file...\n",
        "# if changed, must also update the score.py content according to new file names\n",
        "onnxModelFileName = \"model.onnx\"\n",
        "onnxLabelFileName = \"labels.txt\"\n",
        "\n",
        "onnxModelUrl = \"https://media.githubusercontent.com/media/onnx/models/master/vision/object_detection_segmentation/yolov3/model/yolov3-10.onnx\"\n",
        "onnxModelLabels = \"https://raw.githubusercontent.com/qqwweee/keras-yolo3/master/model_data/coco_classes.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below code snipped downloads Yolo V3 model from [ONNX Model zoo](https://github.com/onnx/models). Model download URLs frequently changes, so if below code fails, please update the source URLs accordingly."
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "# Download the Model files\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "# Download the Tiny Yolo V3 pre-trained model\n",
        "isSolutionModelFilePath = os.path.join(isSolutionPath, onnxModelFileName)\n",
        "if not os.path.exists(isSolutionModelFilePath):\n",
        "    res = urllib.request.urlretrieve(onnxModelUrl, isSolutionModelFilePath)\n",
        "    print(\"Model file downloaded at: {}\".format(isSolutionModelFilePath))\n",
        "else:\n",
        "    print(\"{} already exists here, so not downloading again.\".format(isSolutionModelFilePath))\n",
        "    \n",
        "# Download the labels of the Yolo V3 pre-trained model\n",
        "aixSolutionModelLabelFilePath = os.path.join(isSolutionPath, onnxLabelFileName)\n",
        "if not os.path.exists(isSolutionModelLabelFilePath):\n",
        "    res = urllib.request.urlretrieve(onnxModelLabels, isSolutionModelLabelFilePath)\n",
        "    print(\"Labels file downloaded at: {}\".format(isSolutionModelLabelFilePath))\n",
        "else:\n",
        "    print(\"{} already exists here, so not downloading again.\".format(isSolutionModelLabelFilePath))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## 5.3. Create Inference Engine Wrapper\n",
        "Here we create a class that will have different properties and methods to help scoring, analysing an image data. This class will also help us to specify analytics compute target such as CPU, VPU, FPGA etc. and also debugging features.  \n",
        "\n",
        "<span style=\"color:red; font-weight: bold; font-size:1.1em;\"> [!Important] </span> Specific to this sample, we are using Yolo V3 model. As you can see from the code below:  \n",
        "- Yolo V3 model accepts only raw image bytes with 416 by 416 size.  \n",
        "- We statically coded the image size (416x416) into the code. Because we expect the SCORE method to receive raw bytes in this size. If it is not 416x416 float32, than the code will crash\n",
        "- Why? LVA sends video frames to the Score endpoint. LVA can send any image size and format. Since LVA can send image with 416x416 size, why we need to spend additional compute cycles here for re-sizing an image?"
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "%%writefile $isSolutionPath/score.py\n",
        "import threading\n",
        "import cv2\n",
        "import numpy as np\n",
        "import io\n",
        "import onnxruntime\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import linecache\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(level=logging.DEBUG)\n",
        "\n",
        "def PrintGetExceptionDetails():\n",
        "    exType, exValue, exTraceback = sys.exc_info()\n",
        "\n",
        "    tbFrame = exTraceback.tb_frame\n",
        "    lineNo = exTraceback.tb_lineno\n",
        "    fileName = tbFrame.f_code.co_filename\n",
        "\n",
        "    linecache.checkcache(fileName)\n",
        "    line = linecache.getline(fileName, lineNo, tbFrame.f_globals)\n",
        "\n",
        "    exMessage = '[AIX] Exception:\\n\\tFile name: {0}\\n\\tLine number: {1}\\n\\tLine: {2}\\n\\tValue: {3}'.format(fileName, lineNo, line.strip(), exValue)\n",
        "\n",
        "    logging.info(exMessage)\n",
        "\n",
        "\n",
        "class MLModel:\n",
        "    def __init__(self):\n",
        "        try:\n",
        "            self._modelFileName = 'model.onnx'\n",
        "            self._labelFileName = 'labels.txt'\n",
        "            self._lock = threading.Lock()\n",
        "\n",
        "            with open(self._labelFileName, \"r\") as f:\n",
        "                self._labelList = [l.rstrip() for l in f]\n",
        "            \n",
        "            self._onnxSession = onnxruntime.InferenceSession(self._modelFileName)\n",
        "\n",
        "        except:\n",
        "            PrintGetExceptionDetails()\n",
        "\n",
        "    def Preprocess(self, cvImage):\n",
        "        try:\n",
        "            imageBlob = cv2.cvtColor(cvImage, cv2.COLOR_BGR2RGB)\n",
        "            imageBlob = np.array(imageBlob, dtype='float32')\n",
        "            imageBlob /= 255.\n",
        "            imageBlob = np.transpose(imageBlob, [2, 0, 1])\n",
        "            imageBlob = np.expand_dims(imageBlob, 0)\n",
        "\n",
        "            return imageBlob\n",
        "        except:\n",
        "            PrintGetExceptionDetails()\n",
        "\n",
        "    def Postprocess(self, boxes, scores, indices):\n",
        "        try:\n",
        "            detectedObjects = []\n",
        "\n",
        "            for idx in indices:\n",
        "                idxTuple = (idx[0], idx[2])\n",
        "                temp = [i for i in boxes[idxTuple]]  # temp[1, 0, 3, 2] = xmin, ymin, xmax, ymax\n",
        "                dobj = {\n",
        "                    \"type\" : \"entity\",\n",
        "                    \"entity\" : {\n",
        "                        \"tag\" : {\n",
        "                            \"value\" : self._labelList[idx[1]],\n",
        "                            \"confidence\" : str(scores[tuple(idx)])\n",
        "                        },\n",
        "                        \"box\" : {\n",
        "                            \"l\" : str(temp[1] / 416),\n",
        "                            \"t\" : str(temp[0] / 416),\n",
        "                            \"w\" : str((temp[3] - temp[1]) / 416),\n",
        "                            \"h\" : str((temp[2] - temp[0]) / 416)\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "                detectedObjects.append(dobj)\n",
        "\n",
        "            return detectedObjects\n",
        "        except:\n",
        "            PrintGetExceptionDetails()\n",
        "\n",
        "    def Score(self, cvImage):\n",
        "        try:\n",
        "            with self._lock:\n",
        "                imageBlob = self.Preprocess(cvImage)\n",
        "                boxes, scores, indices = self._onnxSession.run(None, {\"input_1\": imageBlob, \"image_shape\":np.array([[416, 416]], dtype=np.float32)})\n",
        "        \n",
        "            return self.Postprocess(boxes, scores, indices)\n",
        "\n",
        "        except:\n",
        "            PrintGetExceptionDetails()\n",
        "\n",
        "    def About(self):\n",
        "        return str(\"<H1>ONNX Version: \" + onnxruntime.__version__ + \"</H1><BR><H1> App version: v 1.0</H1>\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Score method of the above InferenceEngine class will return a dictionary of inferences in the following form:\n",
        "\n",
        "```\n",
        "        {\n",
        "            \"entity\": {\n",
        "                \"box\": {\n",
        "                    \"h\": 0.3498992351271351,\n",
        "                    \"l\": 0.027884870008988812,\n",
        "                    \"t\": 0.6497463818662655,\n",
        "                    \"w\": 0.212033897746693\n",
        "                },\n",
        "                \"tag\": {\n",
        "                    \"confidence\": 0.9857677221298218,\n",
        "                    \"value\": \"person\"\n",
        "                }\n",
        "            },\n",
        "            \"type\": \"entity\"\n",
        "        },\n",
        "        {\n",
        "            \"entity\": {\n",
        "                \"box\": {\n",
        "                    \"h\": 0.3593513820482337,\n",
        "                    \"l\": 0.6868949751420454,\n",
        "                    \"t\": 0.6334065123374417,\n",
        "                    \"w\": 0.26539528586647726\n",
        "                },\n",
        "                \"tag\": {\n",
        "                    \"confidence\": 0.9851594567298889,\n",
        "                    \"value\": \"person\"\n",
        "                }\n",
        "            },\n",
        "            \"type\": \"entity\"\n",
        "        }\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5-final",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}