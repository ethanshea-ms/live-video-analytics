{
  "cells": [
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "## 5. Build Iot Edge Module - Docker Image\n",
        "If not already, you should run first jupyter notebook (01_setup_environment.ipynb) in this sample to set the global variables."
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### 5.1. Get global variables\n",
        "We will read the previously stored variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import set_key, get_key, find_dotenv\n",
        "envPath = find_dotenv(raise_error_if_not_found=True)\n",
        "\n",
        "isSolutionPath = get_key(envPath, \"isSolutionPath\")\n",
        "containerImageName = get_key(envPath, \"containerImageName\")\n",
        "containerImageName = get_key(envPath, \"containerImageName\")\n",
        "localacrServiceName = get_key(envPath, \"localacrServiceName\")\n",
        "acrServiceName = get_key(envPath, \"acrServiceName\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remove possible python cache from previous local tests\n",
        "!rm -rf $isSolutionPath/__pycache__"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### 5.2 Create Web Application & Server for our ml solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $isSolutionPath/app.py\n",
        "\n",
        "import os\n",
        "from flask import Flask, request, Response\n",
        "import cv2\n",
        "import logging\n",
        "import json\n",
        "import io\n",
        "from score import AnalyticsAPI\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import threading\n",
        "from azure.iot.device import IoTHubModuleClient, MethodResponse\n",
        "\n",
        "# Initial settings of AI model\n",
        "AIX_MODEL_NAME = \"person-vehicle-bike-detection-crossroad-1016\" # see AnalyticsAPI class for full list of models and other possibilities\n",
        "AIX_TARGET_DEVICE = \"CPU\"\n",
        "AIX_MODEL_PRECISION = \"FP32\"\n",
        "AIX_PROBABILITY_THRESHOLD = 0.5\n",
        "AIX_DEBUG_PATH = \"/debug_path/\" # Same value used in Manifest file. So changing this value will affect the manifest file's consistancy\n",
        "\n",
        "app = Flask(__name__)\n",
        "analyticsAPI = AnalyticsAPI(    modelName=AIX_MODEL_NAME, \n",
        "                                modelPrecision=AIX_MODEL_PRECISION, \n",
        "                                targetDev=AIX_TARGET_DEVICE, \n",
        "                                probThreshold=AIX_PROBABILITY_THRESHOLD)\n",
        "\n",
        "# Wait some time to have the API - HW accelerators initialized\n",
        "time.sleep(2)\n",
        "logger = analyticsAPI.logger\n",
        "\n",
        "# Debug flag for writing out processed frames with bounding boxes etc. marked on them.\n",
        "# if set, debug data will be written in to \"/debug_path\" folder, which is bind to host PC's local drive.\n",
        "# Host PC local drive is specified in the Manifest file, and default value is host PC's /tmp/aix_debug folder.\n",
        "# /tmp already exist in host pc but you should manually create and give access credentails to /tmp/aix_debug (or any directory you want...)\n",
        "#\n",
        "# 0 : no debug output\n",
        "# 1 : output frames only if object detected\n",
        "# 2 : output all frames received\n",
        "#\n",
        "AIX_DEBUG = 2\n",
        "\n",
        "# IoT Hub cloud to device method handles\n",
        "# https://docs.microsoft.com/en-us/python/api/azure-iot-device/azure.iot.device?view=azure-python (see IoTHubModuleClient)\n",
        "#\n",
        "def directMethodListener(client):\n",
        "    global analyticsAPI\n",
        "    global AIX_DEBUG\n",
        "    while True:\n",
        "        try:\n",
        "            methodRequest = client.receive_method_request()  # blocking call\n",
        "            logger.info(\"[AI EXT] Method invoked: {0} - {1}\".format(methodRequest.name, methodRequest.payload))\n",
        "\n",
        "            if methodRequest.name == \"SetProbabilityThreshold\":\n",
        "                analyticsAPI.setProbabilityThreshold(float(methodRequest.payload))\n",
        "                callResult = str(analyticsAPI.getProbabilityThreshold())\n",
        "\n",
        "            elif methodRequest.name == \"SetModel\":\n",
        "                analyticsAPI.setModelName(str(methodRequest.payload))\n",
        "                callResult = analyticsAPI.getModelName()\n",
        "\n",
        "            elif methodRequest.name == \"SetModelPrecision\":\n",
        "                analyticsAPI.setModelPrecision(str(methodRequest.payload))\n",
        "                callResult = analyticsAPI.getModelPrecision()\n",
        "\n",
        "            elif methodRequest.name == \"SetTargetDevice\":\n",
        "                analyticsAPI.setTargetDevice(str(methodRequest.payload))\n",
        "                callResult = analyticsAPI.getTargetDevice()\n",
        "\n",
        "            elif methodRequest.name == \"SetDebug\":\n",
        "                AIX_DEBUG = int(methodRequest.payload)\n",
        "                callResult = str(AIX_DEBUG)\n",
        "\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            responsePayload = {\"Success\": \"{0} - {1}\".format(methodRequest.name, callResult)}\n",
        "            methodResponse = MethodResponse(methodRequest.request_id, 200, payload=responsePayload)\n",
        "            client.send_method_response(methodResponse)\n",
        "\n",
        "        except Exception as e:\n",
        "            responsePayload = {\"Exception\": \"{0} - {1}\".format(methodRequest.name, str(e))}\n",
        "            methodResponse = MethodResponse(methodRequest.request_id, 400, payload=responsePayload)\n",
        "            client.send_method_response(methodResponse)\n",
        "\n",
        "#\n",
        "# Initialize IoTHubDeviceClient to listen method calls coming from cloud.\n",
        "#\n",
        "iotHubModuleClient = IoTHubModuleClient.create_from_edge_environment(websockets=True)\n",
        "iotHubModuleClient.connect()\n",
        "\n",
        "# Start IoTHub event callback threads\n",
        "threadDirectMethodListener = threading.Thread(target=directMethodListener, args=(iotHubModuleClient,))\n",
        "threadDirectMethodListener.daemon = True\n",
        "threadDirectMethodListener.start()\n",
        "\n",
        "# TODO: handle twin updates...\n",
        "\n",
        "@app.route(\"/score\", methods = ['POST'])\n",
        "def scoreRRS():\n",
        "    global analyticsAPI\n",
        "    global logger\n",
        "    global AIX_DEBUG\n",
        "    \n",
        "    # uncomment for extended debug log\n",
        "    # logger.info(\"[AI EXT] Received scoring request. Header: {0}\".format(json.dumps(dict(request.headers))))\n",
        "    # logger.info(\"[AI EXT] Received scoring request\")\n",
        "\n",
        "    try:\n",
        "        # We accept only \"image/jpeg\" but there is no reason to not to update below line and allow PNG etc. formats as OpenCV supports many of them...\n",
        "        if request.headers['Content-Type'] != 'image/jpeg':\n",
        "            logger.info(\"[AI EXT] Non JPEG content sent. Exiting the scoring event...\")\n",
        "            return Response(json.dumps({}), status= 415, mimetype ='application/json')\n",
        "\n",
        "        # Before going forward, return not ready, if it is the case...\n",
        "        if not analyticsAPI.initialized:\n",
        "            return  Response(json.dumps({\"status\": analyticsAPI.INF_STAT_NOT_READY}), status= 200, mimetype ='application/json')  \n",
        "\n",
        "        # get request as byte stream\n",
        "        reqBody = request.get_data(False)\n",
        "\n",
        "        # convert from byte stream\n",
        "        inMemFile = io.BytesIO(reqBody)\n",
        "\n",
        "        # load a sample image\n",
        "        inMemFile.seek(0)\n",
        "        fileBytes = np.asarray(bytearray(inMemFile.read()), dtype=np.uint8)\n",
        "        cvImage = cv2.imdecode(fileBytes, cv2.IMREAD_COLOR)\n",
        "\n",
        "        # call scoring function\n",
        "        result = analyticsAPI.score(cvImage)            \n",
        "\n",
        "        color = (255, 0, 0) # in BGR order\n",
        "\n",
        "        if AIX_DEBUG > 0:\n",
        "            jsonResult = json.loads(result)\n",
        "            statusCode = int(jsonResult[\"status\"])\n",
        "            objectCount = 0\n",
        "            \n",
        "            if statusCode == 0:\n",
        "                objectCount = int(jsonResult[\"object_count\"])\n",
        "                if objectCount > 0:\n",
        "                    jsonResult = jsonResult[\"result\"]\n",
        "                    for k in jsonResult:\n",
        "                        detRes = jsonResult[k]\n",
        "                        xmin = int(detRes[\"xmin\"])\n",
        "                        ymin = int(detRes[\"ymin\"])\n",
        "                        xmax = int(detRes[\"xmax\"])\n",
        "                        ymax = int(detRes[\"ymax\"])\n",
        "                        classId = str(detRes[\"label\"])\n",
        "                        confidence = str(detRes[\"confidence\"])\n",
        "\n",
        "                        cv2.rectangle(cvImage, (xmin, ymin), (xmax, ymax), color, 2)\n",
        "                        cv2.putText(cvImage, classId + \" - \" + confidence, (xmin, ymin - 7), cv2.FONT_HERSHEY_COMPLEX, 1, color, 1)\n",
        "\n",
        "            if (AIX_DEBUG > 1) or (objectCount > 0):\n",
        "                camID = request.args.get('cam', default = 0, type = int)\n",
        "                outPath = os.path.join(AIX_DEBUG_PATH, \"cam{0:02d}\".format(camID))\n",
        "                os.makedirs(outPath, exist_ok=True)\n",
        "                outFileName = os.path.join(outPath, str(datetime.datetime.now()).replace(\" \",\"_\") + \".jpg\")\n",
        "\n",
        "                # resizedImg = cv2.resize(cvImage, (800, 600), interpolation = cv2.INTER_AREA)\n",
        "                # retval = cv2.imwrite(outFileName, resizedImg)\n",
        "                retval = cv2.imwrite(outFileName, cvImage)\n",
        "\n",
        "            # Log only in debug mode\n",
        "            logger.info(\"[AI EXT] Sending response. Status: {0} - Count: {1}\".format(statusCode, objectCount))\n",
        "\n",
        "        logger.info(\"[AI EXT] Responding scoring request.\")\n",
        "        return Response(result, status= 200, mimetype ='application/json')\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.info(\"[AI EXT] Exception (scoreRRS): {0}\".format(str(e)))\n",
        "        return Response(json.dumps({}), status= 200, mimetype ='application/json')   \n",
        "    \n",
        "@app.route(\"/\")\n",
        "def healthy():\n",
        "    return \"Healthy\"\n",
        "\n",
        "# Version\n",
        "@app.route('/version', methods = ['GET'])\n",
        "def version_request():\n",
        "    global analyticsAPI\n",
        "    return analyticsAPI.version()\n",
        "\n",
        "# About\n",
        "@app.route('/about', methods = ['GET'])\n",
        "def about_request():\n",
        "    global analyticsAPI\n",
        "    return analyticsAPI.about() + \"<br><br> AIX_DEBUG: \" + str(AIX_DEBUG)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    while not analyticsAPI.initialized:\n",
        "        logger.info(\"[AI EXT] Waiting AI module to be initialized. (app.py)\")\n",
        "        time.sleep(1)\n",
        "        \n",
        "    app.run(host='0.0.0.0', port=5444)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "No need to make any change here but 5444 is the internal port of the webserver app that listens the requests. Later we will map it to different port to expose to external (see next cell)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $isSolutionPath/wsgi.py\n",
        "from app import app as application\n",
        "\n",
        "def create():\n",
        "    print(\"[AI EXT] Initialising lva ai extension web app\")\n",
        "    application.run(host='127.0.0.1', port=5444)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs(os.path.join(isSolutionPath, \"nginx\"), exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Exposed port of the web app is now 5001 (while the internal one is 5444)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $isSolutionPath/nginx/app\n",
        "server {\n",
        "    listen 5001;\n",
        "    server_name _;\n",
        " \n",
        "    location / {\n",
        "    include proxy_params;\n",
        "    proxy_pass http://127.0.0.1:5444;\n",
        "    proxy_connect_timeout 5000s;\n",
        "    proxy_read_timeout 5000s;\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $isSolutionPath/gunicorn_logging.conf\n",
        "\n",
        "[loggers]\n",
        "keys=root, gunicorn.error\n",
        "\n",
        "[handlers]\n",
        "keys=console\n",
        "\n",
        "[formatters]\n",
        "keys=json\n",
        "\n",
        "[logger_root]\n",
        "level=INFO\n",
        "handlers=console\n",
        "\n",
        "[logger_gunicorn.error]\n",
        "level=ERROR\n",
        "handlers=console\n",
        "propagate=0\n",
        "qualname=gunicorn.error\n",
        "\n",
        "[handler_console]\n",
        "class=StreamHandler\n",
        "formatter=json\n",
        "args=(sys.stdout, )\n",
        "\n",
        "[formatter_json]\n",
        "class=jsonlogging.JSONFormatter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $isSolutionPath/kill_supervisor.py\n",
        "import sys\n",
        "import os\n",
        "import signal\n",
        "\n",
        "def write_stdout(s):\n",
        "    sys.stdout.write(s)\n",
        "    sys.stdout.flush()\n",
        "\n",
        "# this function is modified from the code and knowledge found here: http://supervisord.org/events.html#example-event-listener-implementation\n",
        "def main():\n",
        "    while 1:\n",
        "        write_stdout('[AI EXT] READY\\n')\n",
        "        # wait for the event on stdin that supervisord will send\n",
        "        line = sys.stdin.readline()\n",
        "        write_stdout('[AI EXT] Killing supervisor with this event: ' + line);\n",
        "        try:\n",
        "            # supervisord writes its pid to its file from which we read it here, see supervisord.conf\n",
        "            pidfile = open('/tmp/supervisord.pid','r')\n",
        "            pid = int(pidfile.readline());\n",
        "            os.kill(pid, signal.SIGQUIT)\n",
        "        except Exception as e:\n",
        "            write_stdout('[AI EXT] Could not kill supervisor: ' + e.strerror + '\\n')\n",
        "            write_stdout('[AI EXT] RESULT 2\\nOK')\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs(os.path.join(isSolutionPath, \"etc\"), exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $isSolutionPath/etc/supervisord.conf \n",
        "[supervisord]\n",
        "logfile=/tmp/supervisord.log ; (main log file;default $CWD/supervisord.log)\n",
        "logfile_maxbytes=50MB        ; (max main logfile bytes b4 rotation;default 50MB)\n",
        "logfile_backups=10           ; (num of main logfile rotation backups;default 10)\n",
        "loglevel=info                ; (log level;default info; others: debug,warn,trace)\n",
        "pidfile=/tmp/supervisord.pid ; (supervisord pidfile;default supervisord.pid)\n",
        "nodaemon=true                ; (start in foreground if true;default false)\n",
        "minfds=1024                  ; (min. avail startup file descriptors;default 1024)\n",
        "minprocs=200                 ; (min. avail process descriptors;default 200)\n",
        "environment=LD_LIBRARY_PATH=%(ENV_LD_LIBRARY_PATH)s,INTEL_CVSDK_DIR=%(ENV_INTEL_CVSDK_DIR)s,OpenCV_DIR=%(ENV_OpenCV_DIR)s,InferenceEngine_DIR=%(ENV_InferenceEngine_DIR)s,PYTHONPATH=%(ENV_PYTHONPATH)s,INTEL_OPENVINO_DIR=%(ENV_INTEL_OPENVINO_DIR)s,PATH=%(ENV_PATH)s,HDDL_INSTALL_DIR=%(ENV_HDDL_INSTALL_DIR)s,INTEL_OPENVINO_DIR=%(ENV_INTEL_OPENVINO_DIR)s,PATH=%(ENV_PATH)s\n",
        "\n",
        "[program:gunicorn]\n",
        "command=bash -c \"gunicorn --workers 1 -m 007 --timeout 100000 --capture-output --error-logfile - --log-level debug --log-config gunicorn_logging.conf \\\"wsgi:create()\\\"\"\n",
        "directory=/code\n",
        "redirect_stderr=true\n",
        "stdout_logfile =/dev/stdout\n",
        "stdout_logfile_maxbytes=0\n",
        "startretries=2\n",
        "startsecs=20\n",
        "\n",
        "[program:nginx]\n",
        "command=/usr/sbin/nginx -g \"daemon off;\"\n",
        "startretries=2\n",
        "startsecs=5\n",
        "priority=3\n",
        "\n",
        "[eventlistener:program_exit]\n",
        "command=python kill_supervisor.py\n",
        "directory=/code\n",
        "events=PROCESS_STATE_FATAL\n",
        "priority=2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $isSolutionPath/requirements.txt\n",
        "pillow<7.0.0\n",
        "click==6.7\n",
        "configparser==3.5.0\n",
        "Flask==0.12.2\n",
        "gunicorn==19.6.0\n",
        "json-logging-py==0.2\n",
        "MarkupSafe==1.0\n",
        "olefile==0.44\n",
        "requests==2.12.3"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### 5.3. Create Docker File to containerize ml solution and web app server"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TODO: Update Dockerfile to reduce its size... There exist many ways to do it but for simplicity and self explainability we keep as is below."
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "<span style=\"color:red; font-weight: bold; font-size:1.1em;\"> [!Important] </span>  \n",
        "\n",
        "OpenVino Toolkit is a licenced software. Below link probably will not be working for you and you should replace it with your own offline download link. To get your own download link, follow the below instructions:  \n",
        "\n",
        "1) Goto address: https://software.intel.com/en-us/openvino-toolkit/choose-download/free-download-linux  \n",
        "2) Click on \"Register & Download\" button  \n",
        "<img src=\"../doc_imgs/img_03_001.jpg\" width=400 alt=\"> Figure: Register & Download.\"/>  \n",
        "\n",
        "3) Fill in the form and submit  \n",
        "<img src=\"../doc_imgs/img_03_002.jpg\" width=400 alt=\"> Figure: Fill the form.\"/>  \n",
        "\n",
        "4) Over the \"Full Package\" link, right click and get the link which should look like something:  \n",
        "    http://registrationcenter-download.intel.com/akdlm/irc_nas/<SOMECODE\\>/l_openvino_toolkit_p_2020.1.023.tgz  \n",
        "<img src=\"../doc_imgs/img_03_003.jpg\" width=400 alt=\"> Figure: Download link.\"/>  \n",
        "\n",
        "5) In the below cell, set the value of variable \"openVinoToolkitDownloadLink\" to the download link you have"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# As described above, set the value of variable \"openVinoToolkitDownloadLink\" to the download link you have (below is sample URI, just remove it and use your own address)\n",
        "openVinoToolkitDownloadLink = \"http://registrationcenter-download.intel.com/akdlm/irc_nas/16345/l_openvino_toolkit_p_2020.1.023.tgz\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $isSolutionPath/Dockerfile\n",
        "\n",
        "FROM ubuntu:18.04\n",
        "MAINTAINER Mustafa K. <mkasap@microsoft.com>\n",
        "\n",
        "USER root\n",
        "\n",
        "ARG WORK_DIR=/code\n",
        "ENV WORK_DIR ${WORK_DIR}\n",
        "ENV PATH /opt/miniconda/bin:${PATH}\n",
        "\n",
        "RUN mkdir -p ${WORK_DIR}\n",
        "\n",
        "WORKDIR ${WORK_DIR}\n",
        "\n",
        "#\n",
        "# Install base\n",
        "#\n",
        "RUN apt-get update &&\\\n",
        "    apt-get install -y --no-install-recommends \\\n",
        "        # Essentials\n",
        "        wget \\\n",
        "        locales \\\n",
        "        # Python environment\n",
        "        python3 \\\n",
        "        python3-setuptools &&\\\n",
        "    #\n",
        "    # Dependencies: conda\n",
        "    wget --quiet https://repo.anaconda.com/miniconda/Miniconda3-4.5.11-Linux-x86_64.sh -O ${WORK_DIR}/miniconda.sh --no-check-certificate &&\\ \n",
        "    /bin/bash ${WORK_DIR}/miniconda.sh -b -p /opt/miniconda &&\\\n",
        "    #\n",
        "    # Cleaning\n",
        "    /opt/miniconda/bin/conda clean -ya &&\\\n",
        "    rm -rf /opt/miniconda/pkgs &&\\\n",
        "    rm -rf /var/lib/apt/lists/*\n",
        "\n",
        "#\n",
        "# Install OpenVino\n",
        "#\n",
        "#COPY l_openvino_toolkit_p_2020.1.023.tgz ${WORK_DIR}\n",
        "RUN apt-get update &&\\\n",
        "    apt-get install -y --no-install-recommends \\\n",
        "        # Essentials\n",
        "        cpio \\\n",
        "        udev \\\n",
        "        unzip \\\n",
        "        autoconf \\\n",
        "        automake \\\n",
        "        libtool\n",
        "\n",
        "RUN wget --quiet AIX_OPENVINO_TOOLKIT_DOWNLOAD_LINK -O ${WORK_DIR}/l_openvino_toolkit_p_2020.1.023.tgz &&\\\n",
        "    pattern=\"COMPONENTS=DEFAULTS\" &&\\\n",
        "    replacement=\"COMPONENTS=intel-openvino-ie-sdk-ubuntu-bionic__x86_64;intel-openvino-ie-rt-cpu-ubuntu-bionic__x86_64;intel-openvino-ie-rt-vpu-ubuntu-bionic__x86_64;intel-openvino-opencv-lib-ubuntu-bionic__x86_64\" &&\\\n",
        "    tar -xzf l_openvino_toolkit*.tgz &&\\\n",
        "    cd l_openvino_toolkit* &&\\\n",
        "    sed -i \"s/$pattern/$replacement/\" silent.cfg &&\\\n",
        "    sed -i \"s/decline/accept/g\" silent.cfg &&\\\n",
        "    /bin/bash ./install.sh -s silent.cfg &&\\\n",
        "    cd - &&\\\n",
        "    cd /opt/intel/openvino/install_dependencies &&\\\n",
        "    /bin/bash ./install_openvino_dependencies.sh &&\\\n",
        "    # setup environment variables\n",
        "    echo \"source /opt/intel/openvino/bin/setupvars.sh\" >> /root/.bashrc &&\\\n",
        "    #\n",
        "    # Cleaning\n",
        "    cd ${WORK_DIR} &&\\\n",
        "    rm -rf * &&\\\n",
        "    /opt/miniconda/bin/conda clean -ya &&\\\n",
        "    rm -rf /opt/miniconda/pkgs &&\\\n",
        "    rm -rf /var/lib/apt/lists/*\n",
        "\n",
        "#\n",
        "# Set environment variables as in ${INTEL_OPENVINO_DIR}/bin/setupvars.sh\n",
        "ENV INTEL_OPENVINO_DIR /opt/intel/openvino\n",
        "ENV LD_LIBRARY_PATH ${INTEL_OPENVINO_DIR}/opencv/lib:${INTEL_OPENVINO_DIR}/deployment_tools/ngraph/lib:/opt/intel/opencl:${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/external/hddl/lib:${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/external/gna/lib:${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/external/mkltiny_lnx/lib:${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/external/tbb/lib:${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/lib/intel64\n",
        "ENV INTEL_CVSDK_DIR ${INTEL_OPENVINO_DIR}\n",
        "ENV OpenCV_DIR ${INTEL_OPENVINO_DIR}/opencv/cmake\n",
        "ENV InferenceEngine_DIR ${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/share\n",
        "ENV PYTHONPATH ${INTEL_OPENVINO_DIR}/python/python3.7:${INTEL_OPENVINO_DIR}/python/python3:${INTEL_OPENVINO_DIR}/deployment_tools/open_model_zoo/tools/accuracy_checker:${INTEL_OPENVINO_DIR}/deployment_tools/model_optimizer\n",
        "ENV PATH ${INTEL_OPENVINO_DIR}/deployment_tools/model_optimizer:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:${PATH}\n",
        "ENV HDDL_INSTALL_DIR ${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/external/hddl\n",
        "\n",
        "#\n",
        "# Exclude UDEV by rebuilding libusb without UDEV support\n",
        "RUN cp ${INTEL_OPENVINO_DIR}/deployment_tools/inference_engine/external/97-myriad-usbboot.rules /etc/udev/rules.d/ &&\\\n",
        "    ldconfig &&\\\n",
        "    cd /opt && wget --quiet --no-check-certificate http://github.com/libusb/libusb/archive/v1.0.22.zip -O /opt/v1.0.22.zip &&\\\n",
        "    unzip v1.0.22.zip && cd libusb-1.0.22 &&\\\n",
        "    ./bootstrap.sh &&\\\n",
        "    ./configure --disable-udev --enable-shared &&\\\n",
        "    make -j4\n",
        "\n",
        "RUN apt-get update &&\\\n",
        "    apt-get install -y --no-install-recommends libusb-1.0-0-dev &&\\\n",
        "    cd /opt &&\\\n",
        "    rm -rf /var/lib/apt/lists/* &&\\\n",
        "    cd /opt/libusb-1.0.22/libusb &&\\\n",
        "    /bin/mkdir -p '/usr/local/lib' &&\\\n",
        "    /bin/bash ../libtool --mode=install /usr/bin/install -c libusb-1.0.la '/usr/local/lib' &&\\\n",
        "    /bin/mkdir -p '/usr/local/include/libusb-1.0' &&\\\n",
        "    /usr/bin/install -c -m 644 libusb.h '/usr/local/include/libusb-1.0' &&\\\n",
        "    /bin/mkdir -p '/usr/local/lib/pkgconfig' &&\\\n",
        "    cd /opt/libusb-1.0.22/ &&\\\n",
        "    /usr/bin/install -c -m 644 libusb-1.0.pc '/usr/local/lib/pkgconfig' &&\\\n",
        "    ldconfig\n",
        "\n",
        "#\n",
        "# Install ML solution\n",
        "RUN apt-get update && apt-get install -y --no-install-recommends \\\n",
        "    nginx \\\n",
        "    supervisor &&\\\n",
        "    pip install \\\n",
        "        numpy \\\n",
        "        azure-iot-device\n",
        "        \n",
        "ADD . ${WORK_DIR}\n",
        "ADD etc /etc\n",
        "\n",
        "RUN rm -rf /var/lib/apt/lists/* &&\\\n",
        "    rm /etc/nginx/sites-enabled/default &&\\\n",
        "    cp ${WORK_DIR}/nginx/app /etc/nginx/sites-available/ &&\\\n",
        "    ln -s /etc/nginx/sites-available/app /etc/nginx/sites-enabled/ &&\\\n",
        "    pip install -r ${WORK_DIR}/requirements.txt &&\\\n",
        "    /opt/miniconda/bin/conda clean -ya &&\\\n",
        "    rm -rf /opt/miniconda/pkgs &&\\\n",
        "    rm -rf /var/lib/apt/lists/*\n",
        "\n",
        "EXPOSE 5001\n",
        "CMD [\"supervisord\", \"-c\", \"/code/etc/supervisord.conf\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Update docker file with custom environment variable. IoT Edge device's connection string\n",
        "filePath = isSolutionPath+\"/Dockerfile\"\n",
        "file = open(filePath)\n",
        "dockerFileTemplate = file.read()\n",
        "dockerFileTemplate = dockerFileTemplate.replace(\"AIX_OPENVINO_TOOLKIT_DOWNLOAD_LINK\", \"\\\"\"+openVinoToolkitDownloadLink+\"\\\"\")\n",
        "\n",
        "with open(filePath, 'wt', encoding='utf-8') as outputFile:\n",
        "    outputFile.write(dockerFileTemplate)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### 5.4. Create Local Docker Image\n",
        "We create the image locally, without hostring it yet in a container registry like docker.com or ACR or local registry\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash -s \"$containerImageName\" \"$isSolutionPath\"\n",
        "docker build -t $1 --file ./$2/Dockerfile ./$2"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### 5.5. Host the local docker image in local docker registry\n",
        "We will be hosting the docker image on a local registry which is either on the edge device, or on the development device which is on the same network as the edge device. We prefer this method only at the development stage as:\n",
        "- Docker image size ~ 1-2 GB\n",
        "- Hosting image on Azure Container Registry (ACR) means each time we compile the image, we will send it, push it to cloud and then pull all the way back to edge device. In case of low Internet connection bandwidth, this may be an issue or time consuming operation.\n",
        "- There is an option where you can send smaller size DockerFile and dependencies to ACR and compile there. But in this case, 1) again you need to pull back the 1-2 GB size image to edge device 2) Even in case of a small code change in the last layers of the docker image, ACR will re-compile every layer from scratc which may take additional ~40 minutes...\n",
        "\n",
        "So for above reasons, at the development and testing stages, we will use local container registry. Below is very simple steps to create your own docker registry by running the following bash commands manually:  \n",
        "\n",
        "<span style=\"color:red; font-weight: bold; font-size:1.1em;\"> [!Important] </span>  \n",
        "In the below instructions we use **\"mkregistry:55000\"** as static text which is stored in the variable **localacrServiceName**. Value of this variable set in the first step/section of this sample. You can change this value to anything else but in case, you should update the commands in this static text with the new value.\n",
        "\n",
        "\n",
        "1) Create a folder to host local docker registry configuration folder (i.e. we name it \"mkregistry\").\n",
        "```shell\n",
        "mkdir mkregistry\n",
        "```\n",
        "2) Inside the \"mkregistry\" directory, create a congiguration file named \"docker-compose.yml\" with the following content in:\n",
        "\n",
        "```yml\n",
        "version: '3.0'\n",
        " \n",
        "services:\n",
        "  mkregistry:\n",
        "    image: registry:latest\n",
        "    container_name: mkregistry\n",
        "    volumes:\n",
        "      - registry:/var/lib/registry\n",
        "    ports:\n",
        "      - \"55000:5000\"\n",
        "    restart: unless-stopped\n",
        "volumes:\n",
        "  registry:\n",
        "```\n",
        "\n",
        "3) Install \"docker-compose\" tool. Run the following shell command to install it.  \n",
        "```shell\n",
        "sudo apt-get -y install docker-compose\n",
        "```\n",
        "\n",
        "4) Run the following command inside the \"mkregistry\" directory with \"docker-compose.yml\" file in it.  \n",
        "```shell\n",
        "sudo docker-compose up -d\n",
        "```\n",
        "\n",
        "<span style=\"color:red; font-weight: bold; font-size:1.1em;\"> [!Important] </span>  \n",
        "> When you restart the machine etc. you need to re-run above command to start the local regisrty service (you can search for methods to run it as auto run service)\n",
        "when you type \"docker container ls\" shell command. You should see the following line to confirm that the service is running, you can validate with below next step.\n",
        "```\n",
        "f63fd9492a03        registry:latest                              \"/entrypoint.sh /etc…\"    20 hours ago        Up 19 hours         0.0.0.0:55000->5000/tcp                                                mkregistry\n",
        "m\n",
        "```\n",
        "\n",
        "5) In your Internet explorer - web browser, you browse to following address to see the images in your local repository (initially it is empty...)  \n",
        "```\n",
        "http://localhost:55000/v2/_catalog\n",
        "```\n",
        "\n",
        "6) Edit \"hosts\" file to assign a name resolution setting for local docker registry. First open the \"/etc/hosts\" file with your favorite text editor:  \n",
        "```shell\n",
        "sudo nano /etc/hosts\n",
        "```\n",
        "\n",
        "than add the following line under \"127.0.0.0 localhost\"  \n",
        "\n",
        "```shell\n",
        "127.0.0.1\tmkregistry\n",
        "```\n",
        "\n",
        "so the content of \"/etc/hosts\" file should look like something:  \n",
        "```shell\n",
        "127.0.0.1\tlocalhost\n",
        "127.0.0.1\tmkregistry\n",
        "127.0.1.1\tmknuc01\n",
        "\n",
        "# The following lines are desirable for IPv6 capable hosts\n",
        "::1     ip6-localhost ip6-loopback\n",
        "fe00::0 ip6-localnet\n",
        "ff00::0 ip6-mcastprefix\n",
        "ff02::1 ip6-allnodes\n",
        "ff02::2 ip6-allrouters\n",
        "```\n",
        "\n",
        "thats all, now we have local docker registy with following addres: mkregistry:55000  \n",
        "\n",
        "With following code, we will tag our local image and pull it into our local docker registry. So when we deploy our IotEdge manifest to IoT Hub, the edge devices will pull it from this registry. In production stage, we will host the image in ACR, more centric and managable store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash -s \"$containerImageName\" \"$localacrServiceName\"\n",
        "docker tag $1 $2/$1\n",
        "docker push $2/$1 "
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "<span style=\"color:red; font-weight: bold; font-size:1.1em;\"> [!Important] </span>  \n",
        "If you are in production, you can push the image into ACR (and not to local repository as in the above cell). Uncomment and use the following command to push it into ACR. Also dont forget to set the  useACRFlag  to TRUE in the next step/section of the sample where you deploy the image into edge devices. So the edge device will pull modules from the ACR and not from local registry...\n",
        "\n",
        "<span style=\"color:red; font-weight: bold; font-size:1.1em;\"> [!Warning] </span>  \n",
        "Execution of following cell may take up to ~40 - 45 minutes to complete! It will be using Azure Constainer Registry (ACR) to compile a docker image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!az acr build --image $containerImageName --registry $acrServiceName --file ./$isSolutionPath/Dockerfile ./$isSolutionPath"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9-final",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}