{
  "cells": [
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "## 4. Create Azure ML Solution\n",
        "In this section, we will create an inference engine wrapper, a class that will get an image data as input, analyse it and return analysis result as a json formatted data. We will be using Intel OpenVino runtime for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### 4.1. Get global variables\n",
        "We will read the previously stored variables. We need the name of the directory that we will use to store in our ml solution files. We create a directory with the specified directory name (if not already exist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import set_key, get_key, find_dotenv\n",
        "envPath = find_dotenv(raise_error_if_not_found=True)\n",
        "\n",
        "isSolutionPath = get_key(envPath, \"isSolutionPath\")\n",
        "\n",
        "import os\n",
        "if not os.path.exists(isSolutionPath):\n",
        "    os.mkdir(isSolutionPath)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### 4.2. Download OpenVino ML model\n",
        "Download Intel's OpenVino Intermediate Representation models (BIN + XML files) for object detections. We will download multiple models where each have different capabilities. For more details about the capabilities of these models please refer to the links provided below.  \n",
        "\n",
        "ModelZoo can be found at: https://github.com/opencv/open_model_zoo/blob/master/models/intel/index.md  \n",
        "Please click the model names in the ModelZoo page to see model and its performance details.  \n",
        "\n",
        "As reference sample, we will be downloading following models and make them ready to be used in the sample:\n",
        "```\n",
        "# person detectors\n",
        "    \"person-detection-retail-0002\", \n",
        "    \"person-detection-retail-0013\", \n",
        "    \"pedestrian-detection-adas-0002\", \n",
        "    \"pedestrian-detection-adas-binary-0001\", \n",
        "# person + vehicle detectors\n",
        "    \"pedestrian-and-vehicle-detector-adas-0001\",\n",
        "    \"person-vehicle-bike-detection-crossroad-0078\",\n",
        "    \"person-vehicle-bike-detection-crossroad-1016\",\n",
        "# vehicle detectors\n",
        "    \"vehicle-detection-adas-0002\",\n",
        "    \"vehicle-detection-adas-binary-0001\",\n",
        "    \"vehicle-license-plate-detection-barrier-0106\"\n",
        "```\n",
        "\n",
        "Lets download these models and store under the ML Solition directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import yaml\n",
        "import urllib.request\n",
        "\n",
        "\n",
        "def getModel(modelName, isSolutionPath):\n",
        "    mlSolutionModelFilePath = os.path.join(\".\", isSolutionPath, \"models\", modelName)\n",
        "\n",
        "    if not os.path.exists(mlSolutionModelFilePath):\n",
        "        url = \"https://raw.githubusercontent.com/opencv/open_model_zoo/master/models/intel/{0}/model.yml\".format(modelName)\n",
        "        resp = urllib.request.urlopen(url)\n",
        "        yamlFileContent = resp.read()\n",
        "\n",
        "        yamlContent = yaml.load_all(yamlFileContent)\n",
        "        for c in yamlContent:\n",
        "            for k1, v1 in c.items():\n",
        "                if k1 == \"files\":\n",
        "                    for k2, v2 in enumerate(v1):\n",
        "                        for k in v2:\n",
        "                            if k == \"name\":\n",
        "                                modelPathName = v2[k] \n",
        "                            if k == \"source\":\n",
        "                                modelSourceURL = v2[k]\n",
        "                                # Download the model\n",
        "                                pathDownload = os.path.join(mlSolutionModelFilePath, modelPathName)\n",
        "                                headTail = os.path.split(pathDownload) \n",
        "                                os.makedirs(headTail[0], exist_ok=True)\n",
        "                                res = urllib.request.urlretrieve(modelSourceURL, pathDownload)\n",
        "                                print(\"{} downloaded\".format(pathDownload))\n",
        "                                break\n",
        "                    break\n",
        "    else:\n",
        "        print(\"{} already exists here, so not downloading again.\".format(mlSolutionModelFilePath))\n",
        "\n",
        "\n",
        "# see full list of models at Model Zoo...\n",
        "modelNames = [  # person detectors\n",
        "                \"person-detection-retail-0002\", \n",
        "                \"person-detection-retail-0013\", \n",
        "                \"pedestrian-detection-adas-0002\", \n",
        "                \"pedestrian-detection-adas-binary-0001\", \n",
        "                # person + vehicle detectors\n",
        "                \"pedestrian-and-vehicle-detector-adas-0001\",\n",
        "                \"person-vehicle-bike-detection-crossroad-0078\",\n",
        "                \"person-vehicle-bike-detection-crossroad-1016\",\n",
        "                # vehicle detectors\n",
        "                \"vehicle-detection-adas-0002\",\n",
        "                \"vehicle-detection-adas-binary-0001\",\n",
        "                \"vehicle-license-plate-detection-barrier-0106\"]\n",
        "\n",
        "for modelName in modelNames:\n",
        "    print(\"Downloading: {0}\".format(modelName))\n",
        "    getModel(modelName, isSolutionPath)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### 4.3. Create Inferenec Engine Wrapper\n",
        "HEre we create a class that will have different properties and methods to help scoring, analysing an image data. This class will also help us to specify analytics compute target such as CPU, VPU, FPGA etc. and also debugging features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile $isSolutionPath/score.py\n",
        "# Copyright [yyyy] [name of copyright owner]\n",
        "\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import logging\n",
        "import numpy as np\n",
        "import timeit as t\n",
        "from openvino.inference_engine import IENetwork, IEPlugin\n",
        "from collections import OrderedDict\n",
        "import threading\n",
        "\n",
        "logging.basicConfig(level=logging.DEBUG)\n",
        "\n",
        "class AnalyticsAPI:\n",
        "    INF_STAT_OK = 0             # OK\n",
        "    INF_STAT_NOT_READY = 1      # Scoring engine is not ready\n",
        "    INF_STAT_EXCEPTION = 2      # Exception occured whiled inferencing\n",
        "\n",
        "    # targetDev: \"CPU\", \"MYRIAD\", \"GPU\", \"FPGA\"\n",
        "    def __init__(self, modelName, modelPrecision, targetDev, probThreshold, pluginPath=None, cpuExtensions=None):\n",
        "        try:\n",
        "            self.initialized = False\n",
        "\n",
        "            self.logger = logging.getLogger(\"AnalyticsAPILogger\")\n",
        "            self.modelPath = \"./models\"\n",
        "\n",
        "            self.modelName = modelName\n",
        "            self.modelPrecision = modelPrecision\n",
        "            self.targetDev = targetDev\n",
        "            self.probThreshold = probThreshold\n",
        "            self.pluginPath = pluginPath\n",
        "            self.cpuExtensions = cpuExtensions\n",
        "            self._lock = threading.Lock()\n",
        "\n",
        "            self.initEngine()\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.info(\"[AI EXT] Exception (AnalyticsAPI/__init__): {0}\".format(str(e)))\n",
        "            return None\n",
        "\n",
        "    def initEngine(self):\n",
        "        try:\n",
        "            with self._lock:\n",
        "                self.initialized = False\n",
        "                self.logger.info(\"[AI EXT] AnalyticsAPI init start.\")\n",
        "                start = t.default_timer()\n",
        "\n",
        "                self.modelXMLFileName = os.path.join(self.modelPath, self.modelName, self.modelPrecision, self.modelName + \".xml\")\n",
        "                self.modelBINFileName = os.path.join(self.modelPath, self.modelName, self.modelPrecision, self.modelName + \".bin\")\n",
        "\n",
        "                # Init compute target...\n",
        "                self.iePlugin = IEPlugin(device=self.targetDev, plugin_dirs=self.pluginPath)\n",
        "                if self.cpuExtensions and 'CPU' in self.targetDev:\n",
        "                    self.iePlugin.add_cpu_extension(self.cpuExtensions)\n",
        "\n",
        "                ieNet = IENetwork(model=self.modelXMLFileName, weights=self.modelBINFileName)\n",
        "\n",
        "                assert len(ieNet.inputs.keys()) == 1, \"Only single input topologies supported!\"\n",
        "                assert len(ieNet.outputs) == 1, \"Only single output topologies supported!\"\n",
        "                self.inputBlob = next(iter(ieNet.inputs))\n",
        "                self.outBlob = next(iter(ieNet.outputs))\n",
        "\n",
        "                self.ieExecNet = self.iePlugin.load(network=ieNet, num_requests=2)\n",
        "\n",
        "                # Read and pre-process input image\n",
        "                self.ieNetShape = ieNet.inputs[self.inputBlob].shape  # n, c, h, w\n",
        "\n",
        "                self.initialized = True\n",
        "\n",
        "                end = t.default_timer()\n",
        "                self.logger.info(\"[AI EXT] AnalyticsAPI init end. Duration: {0} ms\".format(round((end - start) * 1000, 2)))\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.info(\"[AI EXT] Exception (ScoringAPI/initModel): {0}\".format(str(e)))\n",
        "            return None\n",
        "\n",
        "    def setProbabilityThreshold(self, probThreshold=0.5):\n",
        "        self.probThreshold = probThreshold\n",
        "        self.logger.info(\"[AI EXT] (setProbabilityThreshold): {0}\".format(probThreshold))\n",
        "\n",
        "    def getProbabilityThreshold(self):\n",
        "        return self.probThreshold\n",
        "\n",
        "    def setModel(self, modelName):\n",
        "        self.modelName = modelName\n",
        "        self.initEngine()\n",
        "        self.logger.info(\"[AI EXT] (setModelName): {0}\".format(modelName))\n",
        "\n",
        "    def getModelName(self):\n",
        "        return self.modelName\n",
        "\n",
        "    def setTargetDevice(self, targetDev):\n",
        "        self.targetDev = targetDev\n",
        "        self.initEngine()\n",
        "        self.logger.info(\"[AI EXT] (setTargetDevice): {0}\".format(targetDev))\n",
        "\n",
        "    def getTargetDevice(self):\n",
        "        return self.targetDev\n",
        "\n",
        "    def setModelPrecision(self, modelPrecision):\n",
        "        self.modelPrecision = modelPrecision\n",
        "        self.initEngine()\n",
        "        self.logger.info(\"[AI EXT] (setModelPrecision): {0}\".format(modelPrecision))\n",
        "\n",
        "    def getModelPrecision(self):\n",
        "        return self.modelPrecision\n",
        "\n",
        "    def preprocess(self, cvImage):\n",
        "        ih, iw = cvImage.shape[:-1]\n",
        "        imageHW = (ih, iw)\n",
        "\n",
        "        if (ih, iw) != (self.ieNetShape[2], self.ieNetShape[3]):\n",
        "            cvImage = cv2.resize(cvImage, (self.ieNetShape[3], self.ieNetShape[2]))\n",
        "\n",
        "        cvImage = cvImage.transpose((2, 0, 1))  # Change data layout from HWC to CHW\n",
        "\n",
        "        cvImage = cvImage.reshape(self.ieNetShape)\n",
        "\n",
        "        return cvImage, imageHW\n",
        "\n",
        "    def postprocess(self, infRes, imageHW):\n",
        "        resDict = OrderedDict()\n",
        "\n",
        "        objectId = 0\n",
        "        for obj in infRes[self.outBlob][0][0]:\n",
        "            if obj[2] > self.probThreshold:\n",
        "                xmin = int(obj[3] * imageHW[1])\n",
        "                ymin = int(obj[4] * imageHW[0])\n",
        "                xmax = int(obj[5] * imageHW[1])\n",
        "                ymax = int(obj[6] * imageHW[0])\n",
        "                classId = int(obj[1])\n",
        "\n",
        "                resDict[objectId] = {   \"label\": classId, \n",
        "                                        \"confidence\": round(float(obj[2]), 2), \n",
        "                                        \"xmin\": xmin, \n",
        "                                        \"ymin\": ymin, \n",
        "                                        \"xmax\": xmax, \n",
        "                                        \"ymax\": ymax}\n",
        "                objectId += 1\n",
        "\n",
        "        return resDict\n",
        "\n",
        "    def score(self, cvImage):\n",
        "        try:\n",
        "            #self.logger.info(\"[AI EXT] Scoring start: {0}\".format(self.initialized))\n",
        "            with self._lock:\n",
        "                if self.initialized:\n",
        "                    image, imageHW = self.preprocess(cvImage)\n",
        "\n",
        "                    start = t.default_timer()\n",
        "                    infRes = self.ieExecNet.infer(inputs={self.inputBlob: image})\n",
        "                    end = t.default_timer()\n",
        "                    infTime = round((end - start) * 1000, 4)\n",
        "                    \n",
        "                    resDict = self.postprocess(infRes, imageHW)\n",
        "\n",
        "                    result = {  \"status\": self.INF_STAT_OK,\n",
        "                                \"time\" : infTime,\n",
        "                                \"object_count\" : len(resDict),\n",
        "                                \"result\": resDict}\n",
        "\n",
        "                    result = json.dumps(result)\n",
        "\n",
        "                else:\n",
        "                    resJson = OrderedDict()\n",
        "                    resJson[0] = {\"status\": self.INF_STAT_NOT_READY}\n",
        "                    result = json.dumps(resJson)\n",
        "\n",
        "            #self.logger.info(\"[AI EXT] Scoring end: {0}\".format(self.initialized))\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.info(\"[AI EXT] Exception (ScoringAPI - Score): {0}\".format(str(e)))\n",
        "            resJson = OrderedDict()\n",
        "            resJson[0] = {\"status\": self.INF_STAT_EXCEPTION}\n",
        "            result = json.dumps(resJson)\n",
        "            return result\n",
        "\n",
        "    def version(self):\n",
        "        return \"v 1.0\"\n",
        "\n",
        "    def about(self):\n",
        "        aboutString = \"Engine initialized: {0}<br>ModelName: {1}<br>ModelPrecision: {2}<br>TargetDev: {3}<br>ProbThreshold: {4}<br>PluginPath: {5}<br>CpuExtensions: {6}\".format(self.initialized, self.modelName, self.modelPrecision, self.targetDev, self.probThreshold, self.pluginPath, self.cpuExtensions)\n",
        "        return aboutString"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Score method of the above InferenceEngine class will return the result as Json formated string.  \n",
        "\n",
        "Result will be one of the below three Json string:  \n",
        "\n",
        "1) {\"status\": 1}  \n",
        "Above result means the Inference Engine is not ready for inferencing...\n",
        "\n",
        "2) {\"status\": 2}  \n",
        "Above result means an exception occured while scoring. Details are in the logs...\n",
        "\n",
        "3) Third option is below where status equals to 0. So before you you process the result, you can check the status to see if it contains valid detection data, status code.\n",
        "\n",
        "Fields below are self descriptive and you can refere to above source code for details.\n",
        "\n",
        "\n",
        "```\n",
        "{\n",
        "   \"status\": 0,\n",
        "   \"time\": 45.6475,\n",
        "   \"object_count\": 100,\n",
        "   \"result\": {\n",
        "      \"0\": {\n",
        "         \"label\": 1,\n",
        "         \"confidence\": 1,\n",
        "         \"xmin\": 304,\n",
        "         \"ymin\": 169,\n",
        "         \"xmax\": 398,\n",
        "         \"ymax\": 436\n",
        "      },\n",
        "      \"1\": {\n",
        "         \"label\": 2,\n",
        "         \"confidence\": 0.99,\n",
        "         \"xmin\": 474,\n",
        "         \"ymin\": 201,\n",
        "         \"xmax\": 586,\n",
        "         \"ymax\": 485\n",
        "      },\n",
        "\n",
        "        ...\n",
        "\n",
        "      \"100\": {\n",
        "         \"label\": 5,\n",
        "         \"confidence\": 0.53,\n",
        "         \"xmin\": 385,\n",
        "         \"ymin\": 140,\n",
        "         \"xmax\": 421,\n",
        "         \"ymax\": 246\n",
        "      }\n",
        "   }\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9-final",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}